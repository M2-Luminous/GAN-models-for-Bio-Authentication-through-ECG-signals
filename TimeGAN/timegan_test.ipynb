{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# ------------------------------\n",
    "# 1. Data Loading and Preprocessing\n",
    "# ------------------------------\n",
    "def load_and_preprocess_ecg_data(csv_path=\"data/lead_I_data.csv\"):\n",
    "    \"\"\"\n",
    "    Loads and preprocesses ECG data from CSV, skipping the header row.\n",
    "    \n",
    "    Expected CSV:\n",
    "      - First row: header (skipped)\n",
    "      - Remaining rows: ~987 samples\n",
    "      - 5000 columns: time steps\n",
    "      \n",
    "    Processing:\n",
    "      1. Load CSV and skip the first row.\n",
    "      2. Convert to a NumPy array.\n",
    "      3. Scale values to [0,1] using MinMaxScaler.\n",
    "      4. Reshape to [samples, timesteps, 1] (one ECG channel).\n",
    "    \n",
    "    Returns:\n",
    "        data_scaled: np.array of shape (num_samples, 5000, 1)\n",
    "        scaler: fitted MinMaxScaler (for later inversion if needed)\n",
    "    \"\"\"\n",
    "    # Skip the header row with skiprows=1\n",
    "    df = pd.read_csv(csv_path, header=None, skiprows=1)\n",
    "    data = df.values  # Expected shape: (987, 5000)\n",
    "    \n",
    "    scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "    data_scaled = scaler.fit_transform(data)\n",
    "    \n",
    "    # Reshape to [samples, timesteps, features]\n",
    "    data_scaled = data_scaled.reshape(data_scaled.shape[0], data_scaled.shape[1], 1)\n",
    "    \n",
    "    return data_scaled, scaler\n",
    "\n",
    "# Load the ECG data\n",
    "ecg_data_np, ecg_scaler = load_and_preprocess_ecg_data()\n",
    "print(\"ECG data shape:\", ecg_data_np.shape)  # Expected: (987, 5000, 1)\n",
    "\n",
    "# Convert to torch.Tensor\n",
    "ecg_data_tensor = torch.tensor(ecg_data_np, dtype=torch.float32)\n",
    "\n",
    "# Create a DataLoader\n",
    "batch_size = 32\n",
    "dataset = TensorDataset(ecg_data_tensor)\n",
    "data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------\n",
    "# 2. Define the Networks (Generator, Recovery, Discriminator)\n",
    "# ------------------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Generator: maps noise (z) to a latent representation\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_dim, hidden_dim, num_layers, seq_len):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            z_dim (int): Dimensionality of the input noise.\n",
    "            hidden_dim (int): Latent space dimension.\n",
    "            num_layers (int): Number of GRU layers.\n",
    "            seq_len (int): Length of the time series.\n",
    "        \"\"\"\n",
    "        super(Generator, self).__init__()\n",
    "        self.seq_len = seq_len\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.gru = nn.GRU(input_size=z_dim,\n",
    "                          hidden_size=hidden_dim,\n",
    "                          num_layers=num_layers,\n",
    "                          batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.tanh = nn.Tanh()\n",
    "        \n",
    "    def forward(self, z):\n",
    "        out, _ = self.gru(z)  # (batch_size, seq_len, hidden_dim)\n",
    "        out = self.fc(out)\n",
    "        out = self.tanh(out)\n",
    "        return out\n",
    "\n",
    "# Recovery: maps the latent representation to ECG data\n",
    "class Recovery(nn.Module):\n",
    "    def __init__(self, hidden_dim, num_layers, seq_len, output_dim=1):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            hidden_dim (int): Latent space dimension.\n",
    "            num_layers (int): Number of GRU layers.\n",
    "            seq_len (int): Length of the time series.\n",
    "            output_dim (int): Dimension of the output signal (1 for ECG).\n",
    "        \"\"\"\n",
    "        super(Recovery, self).__init__()\n",
    "        self.gru = nn.GRU(input_size=hidden_dim,\n",
    "                          hidden_size=hidden_dim,\n",
    "                          num_layers=num_layers,\n",
    "                          batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        self.tanh = nn.Tanh()  # Assumes data scaled to [-1,1] or [0,1]\n",
    "        \n",
    "    def forward(self, h):\n",
    "        out, _ = self.gru(h)  # (batch_size, seq_len, hidden_dim)\n",
    "        out = self.fc(out)    # (batch_size, seq_len, output_dim)\n",
    "        out = self.tanh(out)\n",
    "        return out\n",
    "\n",
    "# Discriminator: distinguishes real ECG from fake ECG\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_dim=1, hidden_dim=24, num_layers=3, seq_len=5000):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input_dim (int): Dimension of input signal (1 for ECG).\n",
    "            hidden_dim (int): Hidden dimension for the GRU.\n",
    "            num_layers (int): Number of GRU layers.\n",
    "            seq_len (int): Length of the time series.\n",
    "        \"\"\"\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.gru = nn.GRU(input_size=input_dim,\n",
    "                          hidden_size=hidden_dim,\n",
    "                          num_layers=num_layers,\n",
    "                          batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out, _ = self.gru(x)  # (batch_size, seq_len, hidden_dim)\n",
    "        last_out = out[:, -1, :]  # Use the last time step as summary\n",
    "        out = self.fc(last_out)\n",
    "        out = self.sigmoid(out)\n",
    "        return out\n",
    "\n",
    "# Hyperparameters for networks\n",
    "seq_len = 5000\n",
    "z_dim = 24\n",
    "hidden_dim = 24\n",
    "num_layers = 3\n",
    "\n",
    "# Instantiate networks and move to device\n",
    "G = Generator(z_dim=z_dim, hidden_dim=hidden_dim, num_layers=num_layers, seq_len=seq_len).to(device)\n",
    "R = Recovery(hidden_dim=hidden_dim, num_layers=num_layers, seq_len=seq_len, output_dim=1).to(device)\n",
    "D = Discriminator(input_dim=1, hidden_dim=hidden_dim, num_layers=num_layers, seq_len=seq_len).to(device)\n",
    "\n",
    "# ------------------------------\n",
    "# 3. Define Optimizers and Loss Function\n",
    "# ------------------------------\n",
    "lr = 0.0002\n",
    "optimizer_G = optim.Adam(list(G.parameters()) + list(R.parameters()), lr=lr, betas=(0.5, 0.999))\n",
    "optimizer_D = optim.Adam(D.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------\n",
    "# 4. Full Training Loop (50 epochs, plotting every 5 epochs)\n",
    "# ------------------------------\n",
    "num_epochs = 20\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    for batch in data_loader:\n",
    "        real_ecg = batch[0].to(device)  # Shape: (batch_size, seq_len, 1)\n",
    "        current_bs = real_ecg.size(0)\n",
    "        \n",
    "        # Labels for real and fake data\n",
    "        real_labels = torch.ones(current_bs, 1).to(device)\n",
    "        fake_labels = torch.zeros(current_bs, 1).to(device)\n",
    "        \n",
    "        # --- Train Discriminator ---\n",
    "        optimizer_D.zero_grad()\n",
    "        \n",
    "        # Discriminator loss on real data\n",
    "        outputs_real = D(real_ecg)\n",
    "        loss_D_real = criterion(outputs_real, real_labels)\n",
    "        \n",
    "        # Generate fake ECG:\n",
    "        noise = torch.randn(current_bs, seq_len, z_dim).to(device)\n",
    "        fake_latent = G(noise)\n",
    "        fake_ecg = R(fake_latent)\n",
    "        \n",
    "        outputs_fake = D(fake_ecg.detach())  # Detach to avoid gradient flow into G & R\n",
    "        loss_D_fake = criterion(outputs_fake, fake_labels)\n",
    "        \n",
    "        loss_D = loss_D_real + loss_D_fake\n",
    "        loss_D.backward()\n",
    "        optimizer_D.step()\n",
    "        \n",
    "        # --- Train Generator + Recovery (Combined Generator) ---\n",
    "        optimizer_G.zero_grad()\n",
    "        \n",
    "        noise = torch.randn(current_bs, seq_len, z_dim).to(device)\n",
    "        fake_latent = G(noise)\n",
    "        fake_ecg = R(fake_latent)\n",
    "        \n",
    "        outputs = D(fake_ecg)\n",
    "        loss_G = criterion(outputs, real_labels)  # Try to fool D: label fake as real\n",
    "        \n",
    "        loss_G.backward()\n",
    "        optimizer_G.step()\n",
    "    \n",
    "    print(f\"Epoch [{epoch}/{num_epochs}], Loss D: {loss_D.item():.4f}, Loss G: {loss_G.item():.4f}\")\n",
    "    \n",
    "    # Every 5 epochs, plot one real and one fake ECG sample\n",
    "    if epoch % 1 == 0:\n",
    "        with torch.no_grad():\n",
    "            # Use the first sample from the last batch as real ECG for plotting\n",
    "            real_sample = real_ecg[0].cpu().numpy().squeeze()\n",
    "            # Generate one fake ECG sample\n",
    "            noise = torch.randn(1, seq_len, z_dim).to(device)\n",
    "            fake_sample = R(G(noise)).cpu().numpy().squeeze()\n",
    "            \n",
    "        plt.figure(figsize=(12, 4))\n",
    "        plt.plot(real_sample, label=\"Real ECG\")\n",
    "        plt.plot(fake_sample, label=\"Fake ECG\", alpha=0.8)\n",
    "        plt.title(f\"Epoch {epoch}\")\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
